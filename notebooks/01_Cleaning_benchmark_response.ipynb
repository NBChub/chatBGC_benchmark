{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef46dd-8249-4c1d-9340-3a4323784946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install \"altair[all]\"\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9ed75-c0b0-4827-9a6d-8a5411355648",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbgc_version\t= \"0.2.1-alpha\"\n",
    "benchmark_version = \"v0.2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c6734-5d42-4958-8590-35c1fcef074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../result/benchmark_result_{chatbgc_version}_{benchmark_version}.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d02f8d-67a1-4701-be6c-d3ef61774404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [\"id\", \"question\", \"difficulty\", \"model\", \"llm_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d01b87-1b5b-442b-8563-18ae5e2d5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_json(\"../test/question_sql_pair.json\")\n",
    "df.loc[:, \"sql_query_success\"] = True\n",
    "avalaible_models = {\"ollama\" : [\"llama3.1_70b\", \"llama3.1_8b\",\n",
    "                                \"mistral-nemo\", \"mistral_7b\", \n",
    "                                \"gemma2_9b\", \"gemma2_27b\", \n",
    "                                \"mixtral_8x7b\", \"mixtral_8x22b\",\n",
    "                                #\"sqlcoder:7b\", \"sqlcoder:15b\", \"sqlcoder:70b\"\n",
    "                               ],\n",
    "                    \"openai_chat\" : [\"gpt-3.5-turbo\", \"gpt-4o\", \"gpt-4o-mini\"]\n",
    "                   }\n",
    "\n",
    "for q in df_question.index:\n",
    "    question_id = df_question.loc[q, \"id\"]\n",
    "    for iteration in [1, 2, 3]:\n",
    "        for llm_type, models in avalaible_models.items():\n",
    "            for model in models:\n",
    "                model.replace(\":\", \"_\")\n",
    "                index_name = f\"Q_{str(question_id).zfill(2)}__{llm_type}__{model}__RAG_benchmark__iteration_{iteration}\"\n",
    "                if index_name not in df.index:\n",
    "                    for col in df_question.columns:\n",
    "                        value = df_question.loc[q, col]\n",
    "                        if col == \"sql\":\n",
    "                            col = \"answer_sql_expected\"\n",
    "                        elif col == \"answer\":\n",
    "                            col = \"answer_summary_expected\"\n",
    "                        df.loc[index_name, col] = value\n",
    "                        df.loc[index_name, \"chatbgc_version\"] = chatbgc_version\n",
    "                        df.loc[index_name, \"benchmark_version\"] = benchmark_version\n",
    "                        df.loc[index_name, \"model\"] = model\n",
    "                        df.loc[index_name, \"llm_type\"] = llm_type\n",
    "                        df.loc[index_name, \"sql_query_success\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23a634-5042-47f2-b123-d8919d73f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"1.Refined_benchmark_response.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5a44d-51ee-4d5c-a0f8-b617221a1c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451fc296-2464-4534-b81e-6767e51ff241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb6e6f-dcdb-4cc4-a39b-ef3f6cbe592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../result/gpt-4o/chatbgc_{chatbgc_version}/benchmark_{benchmark_version}/iteration_2/benchmark.log\", \"r\") as f:\n",
    "    benchmark_log = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6388bd-2762-4251-83ac-88ead01ae7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = {}\n",
    "ctr = 0\n",
    "for num, line in enumerate(benchmark_log):\n",
    "    if 'INFO - Processing question' in line:\n",
    "        print(\"\\n-----------\")\n",
    "        print(num, line)\n",
    "        start = num\n",
    "        ctr += 1\n",
    "    if 'processed successfully' in line:\n",
    "        print(num, line)\n",
    "        stop = num\n",
    "        log_data[ctr] = [start, stop]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab8362-d983-4df2-9321-54770110a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aceb71-bad5-41d0-927b-7d6a68c6a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "benchmark_log[log_data[q][0]:log_data[q][1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eeb0ee-5755-41d4-b19a-08b18929c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 3\n",
    "benchmark_log[log_data[q][0]:log_data[q][1]+1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
