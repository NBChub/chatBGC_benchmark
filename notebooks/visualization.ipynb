{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef46dd-8249-4c1d-9340-3a4323784946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install \"altair[all]\"\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e9ed75-c0b0-4827-9a6d-8a5411355648",
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbgc_version\t= \"0.2.1\"\n",
    "benchmark_version = \"02d2c72\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c6734-5d42-4958-8590-35c1fcef074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"../result/benchmark_result_{chatbgc_version}_{benchmark_version}.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d02f8d-67a1-4701-be6c-d3ef61774404",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, [\"id\", \"question\", \"difficulty\", \"model\", \"llm_type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d01b87-1b5b-442b-8563-18ae5e2d5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_question = pd.read_json(\"../test/question_sql_pair.json\")\n",
    "df.loc[:, \"success\"] = True\n",
    "avalaible_models = {\"ollama\" : [\"gemma2_9b\", \"gemma2_27b\", \"llama3.1_8b\", \"mistral-nemo\"],\n",
    "                    \"openai_chat\" : [\"gpt-4o\", \"gpt-4o-mini\"]\n",
    "                   }\n",
    "for q in df_question.index:\n",
    "    question_id = df_question.loc[q, \"id\"]\n",
    "    for iteration in [1, 2, 3]:\n",
    "        for llm_type, models in avalaible_models.items():\n",
    "            for model in models:\n",
    "                index_name = f\"Q_{str(question_id).zfill(2)}__{llm_type}__{model}__RAG_benchmark__iteration_{iteration}\"\n",
    "                if index_name not in df.index:\n",
    "                    for col in df_question.columns:\n",
    "                        value = df_question.loc[q, col]\n",
    "                        if col == \"sql\":\n",
    "                            col = \"answer_sql_expected\"\n",
    "                        elif col == \"answer\":\n",
    "                            col = \"answer_summary_expected\"\n",
    "                        df.loc[index_name, col] = value\n",
    "                        df.loc[index_name, \"chatbgc_version\"] = chatbgc_version\n",
    "                        df.loc[index_name, \"benchmark_version\"] = benchmark_version\n",
    "                        df.loc[index_name, \"model\"] = model\n",
    "                        df.loc[index_name, \"llm_type\"] = llm_type\n",
    "                        df.loc[index_name, \"success\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969e40bc-9699-44bc-ac94-2ad606c70934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.model == \"gpt-4o\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e7ba7-e68a-453b-aac7-891d962c228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom order for difficulty\n",
    "difficulty_order = ['Easy', 'Medium', 'Hard']\n",
    "\n",
    "# Calculate the number of successes per model\n",
    "model_success_order = df[df['success'] == True].groupby('model').size().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# Group by difficulty, model, and success and count occurrences\n",
    "grouped = df.groupby(['difficulty', 'model', 'success']).size().reset_index(name='count')\n",
    "\n",
    "# Create selection for interactivity\n",
    "selection = alt.selection_point(fields=['success'])\n",
    "\n",
    "# Plotting with Altair\n",
    "chart = alt.Chart(grouped).mark_bar().encode(\n",
    "    x=alt.X('count:Q', stack='normalize', title='Success Rate'),\n",
    "    y=alt.Y('difficulty:O', title=None, sort=difficulty_order),\n",
    "    color=alt.Color('success:N', title='Success'),\n",
    "    order=alt.Order('success', sort='descending'),\n",
    "    row=alt.Row('model:N', title=None, sort=model_success_order),\n",
    "    opacity=alt.condition(selection, alt.value(1), alt.value(0.2))\n",
    ").add_params(\n",
    "    selection\n",
    ").properties(\n",
    "    title='Success Count by Difficulty and Model',\n",
    "    height=100\n",
    ")\n",
    "\n",
    "# Display the chart\n",
    "chart.show()\n",
    "\n",
    "# Save the chart as an SVG file\n",
    "outfile = Path(f\"../figures/benchmark_success_{chatbgc_version}_{benchmark_version}.svg\")\n",
    "outfile.parent.mkdir(exist_ok=True, parents=True)\n",
    "chart.save(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb6e6f-dcdb-4cc4-a39b-ef3f6cbe592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../result/gpt-4o/chatbgc_{chatbgc_version}/benchmark_{benchmark_version}/iteration_2/benchmark.log\", \"r\") as f:\n",
    "    benchmark_log = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6388bd-2762-4251-83ac-88ead01ae7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = {}\n",
    "ctr = 0\n",
    "for num, line in enumerate(benchmark_log):\n",
    "    if 'INFO - Processing question' in line:\n",
    "        print(\"\\n-----------\")\n",
    "        print(num, line)\n",
    "        start = num\n",
    "        ctr += 1\n",
    "    if 'processed successfully' in line:\n",
    "        print(num, line)\n",
    "        stop = num\n",
    "        log_data[ctr] = [start, stop]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab8362-d983-4df2-9321-54770110a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aceb71-bad5-41d0-927b-7d6a68c6a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 1\n",
    "benchmark_log[log_data[q][0]:log_data[q][1]+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eeb0ee-5755-41d4-b19a-08b18929c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 3\n",
    "benchmark_log[log_data[q][0]:log_data[q][1]+1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
